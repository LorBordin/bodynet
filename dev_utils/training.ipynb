{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movenet Training\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LorBordin/bodynet/blob/master/dev_utils/training.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "## 1.1 Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/LorBordin/bodynet\n",
    "!pip install -q -U -r bodynet/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bodynet to path\n",
    "import sys\n",
    "sys.path.append(\"./bodynet\")\n",
    "\n",
    "# Connect with drive to load the dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DS_PATH='gdrive/MyDrive/bodynet_ds/tfrecords.zip'\n",
    "\n",
    "# Load the data from gdrive\n",
    "if not os.path.isdir(\"/content/dataset\"):\n",
    "  !unzip $DS_PATH -d /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Training settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from bodypose.training.metrics import avgMDE_2D, avgMDE_2D_RAW, Accuracy\n",
    "from bodypose.training.metrics import RegressionLoss2D, AuxiliaryLoss  \n",
    "from bodypose.training.architecture.custom_layers import get_max_mask\n",
    "from bodypose.training.preprocessing import load_TFRecords_dataset\n",
    "from bodypose.training.preprocessing import augmentations\n",
    "from bodypose.training.architecture import MoveNet\n",
    "\n",
    "from bodypose.demo.graphics import draw_keypoints\n",
    "\n",
    "import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "STRIDES = (32, 16, 8, 4)\n",
    "NUM_KPTS = len(cfg.MPII_KEYPOINT_DICT)\n",
    "\n",
    "GRID_SIZE = INPUT_SHAPE[0] // STRIDES[-1]\n",
    "\n",
    "if not os.path.exists(\"saved_models\"):  \n",
    "  os.mkdir(\"saved_models\")\n",
    "  \n",
    "MODEL_PATH = f\"./saved_models/movenet_{INPUT_SHAPE[0]}.models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [\n",
    "    augmentations.VerticalShift(max_shift_range=.15),\n",
    "    augmentations.HorizontalShift(max_shift_range=.15),\n",
    "    augmentations.HorizontalFlip(probability=.5, keypoints_idxs=cfg.MPII_KEYPOINT_IDXS)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = list(paths.list_files(\"./tfrecords/mpii/train/\"))\n",
    "valid_paths = list(paths.list_files(\"./tfrecords/mpii/validation/\"))\n",
    "np.random.shuffle(train_paths)\n",
    "np.random.shuffle(valid_paths)\n",
    "\n",
    "train_ds = load_TFRecords_dataset(\n",
    "    filePaths=train_paths, \n",
    "    batch_size = 32,\n",
    "    target_size = INPUT_SHAPE[:2],\n",
    "    grid_dim = GRID_SIZE,\n",
    "    augmentations = augs,\n",
    "    roi_thresh = 0.9\n",
    "    )\n",
    "\n",
    "val_ds = load_TFRecords_dataset(\n",
    "    filePaths=valid_paths, \n",
    "    batch_size = 32,\n",
    "    target_size = INPUT_SHAPE[:2],\n",
    "    grid_dim = GRID_SIZE,\n",
    "    augmentations = [],\n",
    "    roi_thresh = 0.9\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, (y1, y2) in train_ds.take(1):\n",
    "    print(img.shape)\n",
    "    print(y1.shape)\n",
    "    print(y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 ms ± 15 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "model = MoveNet(\n",
    "    input_shape = INPUT_SHAPE, \n",
    "    strides = STRIDES, \n",
    "    num_joints = NUM_KPTS, \n",
    "    alpha = .5, \n",
    "    use_depthwise = True\n",
    "    )\n",
    "\n",
    "img = (np.random.uniform(\n",
    "    0, 255, (1,) + INPUT_SHAPE\n",
    "    ).astype(\"uint8\") / 255).astype(np.float32)\n",
    "\n",
    "%timeit model(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam()\n",
    "moving_avg_opt = tfa.optimizers.MovingAverage(adam)\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    return  lr\n",
    "    #if epoch < 10:\n",
    "    #    return lr\n",
    "    #else:\n",
    "    #    return lr * tf.math.exp(-0.1)\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        MODEL_PATH,\n",
    "        monitor = \"output_1_val_avgMDE_2D\",\n",
    "        save_best_only = True,\n",
    "        save_weights_only = True,\n",
    "        initial_value_threshold=None,\n",
    "        ),\n",
    "    keras.callbacks.LearningRateScheduler(\n",
    "        scheduler\n",
    "        ),\n",
    "    tfa.callbacks.AverageModelCheckpoint(\n",
    "        filepath=MODEL_PATH, \n",
    "        update_weights=True\n",
    "        )\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer = moving_avg_opt,\n",
    "    loss = {'output_1': RegressionLoss2D, 'output_2': AuxiliaryLoss},\n",
    "    loss_weights = [1., 1.],\n",
    "    metrics = {'output_1': [Accuracy, avgMDE_2D_RAW, avgMDE_2D]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cp -r ./saved_models/* /content/gdrive/MyDrive/bodynet_ds/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, (y1, y2) in val_ds.take(1):\n",
    "    print(img.shape)\n",
    "    print(y1.shape)\n",
    "    print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "for i in range(10):\n",
    "    pred_img = ((img[i].numpy() + 1) * 127.5).astype('uint8').copy()\n",
    "    true_img = ((img[i].numpy() + 1) * 127.5).astype('uint8').copy()\n",
    "\n",
    "    preds, heatmaps = model.predict(img[i:i+1])\n",
    "    preds = preds[0, :, :3]\n",
    "    preds = preds[:, [1,2,0]]\n",
    "\n",
    "    # Heatmaps\n",
    "    kptsmask = get_max_mask(heatmaps.reshape(-1, GRID_SIZE, GRID_SIZE, NUM_KPTS+1))\n",
    "    kptsmap = kptsmask[0, :, :, 1:].numpy().sum(axis=-1)\n",
    "    kptsmap = cv2.resize(kptsmap, INPUT_SHAPE[:2])\n",
    "\n",
    "    centremap = heatmaps[0, :, 0].reshape(GRID_SIZE, GRID_SIZE)\n",
    "    centremap = cv2.resize(centremap, INPUT_SHAPE[:2])\n",
    "\n",
    "    # Weighted heatmaps\n",
    "    #w_kptsmask = get_max_mask(w_heatmaps.reshape(-1, GRID_SIZE, GRID_SIZE, NUM_KPTS+1))\n",
    "    #w_kptsmap = w_kptsmask[0, :, :, 1:].numpy().sum(axis=-1)\n",
    "    #w_kptsmap = cv2.resize(w_kptsmap, INPUT_SHAPE[:2])\n",
    "\n",
    "    #w_centremap = w_heatmaps[0, :, 0].reshape(56, 56)\n",
    "    #w_centremap = cv2.resize(w_centremap, INPUT_SHAPE[:2])\n",
    "\n",
    "\n",
    "    labels = y1[i, :, :3].numpy()\n",
    "    labels = labels[:, [1,2,0]]\n",
    "\n",
    "    pred_img = draw_keypoints(pred_img, preds, .5, cfg.MPII_KEYPOINT_DICT)\n",
    "    true_img = draw_keypoints(true_img, labels, .5, cfg.MPII_KEYPOINT_DICT)\n",
    "\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.set_figheight(20)\n",
    "    fig.set_figwidth(20)\n",
    "\n",
    "    axs[0,0].imshow(true_img)\n",
    "    axs[0,0].axis('off')\n",
    "    axs[0,0].set_title(\"Original\")\n",
    "\n",
    "    axs[0,1].imshow(pred_img)\n",
    "    axs[0,1].axis('off')\n",
    "    axs[0,1].set_title(\"Predicted\")\n",
    "    \n",
    "    axs[1,0].imshow(pred_img, alpha=.5)\n",
    "    axs[1,0].imshow(centremap,  alpha=.5)\n",
    "    axs[1,0].axis('off')\n",
    "    axs[1,0].set_title(\"Centremap\")\n",
    "    \n",
    "    axs[1,1].imshow(pred_img, alpha=.5)\n",
    "    axs[1,1].imshow(kptsmap,  alpha=.5)\n",
    "    axs[1,1].axis('off')\n",
    "    axs[1,1].set_title(\"Keypointsmap\")\n",
    "    \n",
    "    #axs[2,0].imshow(pred_img, alpha=.5)\n",
    "    #axs[2,0].imshow(w_centremap,  alpha=.5)\n",
    "    #axs[2,0].axis('off')\n",
    "    #axs[2,0].set_title(\"Weighted Centremap\")\n",
    "    \n",
    "    #axs[2,1].imshow(pred_img, alpha=.5)\n",
    "    #axs[2,1].imshow(w_kptsmap,  alpha=.5)\n",
    "    #axs[2,1].axis('off')\n",
    "    #axs[2,1].set_title(\"Weighted Keypointsmap\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6bf254e122c73ff488b8766148b4203e9f38b207ede26a956107a11310590f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
