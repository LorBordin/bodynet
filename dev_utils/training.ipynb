{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movenet Training\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LorBordin/bodynet/blob/heatmaps/dev_utils/training.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "## 1.1 Prepare environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --branch heatmaps https://github.com/LorBordin/bodynet.git\n",
    "!pip install -q -U -r bodynet/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add bodynet to path\n",
    "import sys\n",
    "sys.path.append(\"./bodynet\")\n",
    "\n",
    "# Connect with drive to load the dataset\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DS_PATH='gdrive/MyDrive/bodynet_ds/tfrecords.zip'\n",
    "\n",
    "# Load the data from gdrive\n",
    "if not os.path.isdir(\"/content/dataset\"):\n",
    "  !unzip $DS_PATH -d /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Training settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from imutils import paths\n",
    "import matplotlib as mpl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from bodypose.training.architecture.custom_layers import get_max_mask\n",
    "from bodypose.training.preprocessing import load_TFRecords_dataset\n",
    "from bodypose.training.preprocessing import augmentations\n",
    "from bodypose.training.metrics import ClassificationLoss, RegrCoordsLoss, RegrCoordsLossRaw\n",
    "from bodypose.training.metrics import Accuracy, avgMDE_2D, avgMDE_2D_Raw\n",
    "from bodypose.training.architecture import MoveNet\n",
    "\n",
    "from bodypose.demo.graphics import draw_keypoints\n",
    "\n",
    "import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (224, 224, 3)\n",
    "STRIDES = (32, 16, 8, 4)\n",
    "NUM_KPTS = len(cfg.MPII_KEYPOINT_DICT)\n",
    "\n",
    "GRID_SIZE = INPUT_SHAPE[0] // STRIDES[-1]\n",
    "\n",
    "if not os.path.exists(\"saved_models\"):  \n",
    "  os.mkdir(\"saved_models\")\n",
    "  \n",
    "MODEL_PATH = f\"./saved_models/movenet_{INPUT_SHAPE[0]}.models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = [\n",
    "    augmentations.VerticalShift(max_shift_range=.15),\n",
    "    augmentations.HorizontalShift(max_shift_range=.15),\n",
    "    augmentations.HorizontalFlip(probability=.5, keypoints_idxs=cfg.MPII_KEYPOINT_IDXS)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = list(paths.list_files(\"./tfrecords/mpii/train/\"))\n",
    "valid_paths = list(paths.list_files(\"./tfrecords/mpii/validation/\"))\n",
    "np.random.shuffle(train_paths)\n",
    "np.random.shuffle(valid_paths)\n",
    "\n",
    "train_ds = load_TFRecords_dataset(\n",
    "    filePaths=train_paths, \n",
    "    batch_size = 32,\n",
    "    target_size = INPUT_SHAPE[:2],\n",
    "    grid_dim = GRID_SIZE,\n",
    "    augmentations = augs,\n",
    "    roi_thresh = 1.\n",
    "    )\n",
    "\n",
    "val_ds = load_TFRecords_dataset(\n",
    "    filePaths=valid_paths, \n",
    "    batch_size = 32,\n",
    "    target_size = INPUT_SHAPE[:2],\n",
    "    grid_dim = GRID_SIZE,\n",
    "    augmentations = [],\n",
    "    roi_thresh = 1.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, (y1, y2) in train_ds.take(1):\n",
    "    print(img.shape)\n",
    "    print(y1.shape)\n",
    "    print(y2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126 ms ± 15 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "model = MoveNet(\n",
    "    input_shape = INPUT_SHAPE, \n",
    "    strides = STRIDES, \n",
    "    num_joints = NUM_KPTS, \n",
    "    alpha = .5, \n",
    "    use_depthwise = True,\n",
    "    use_postproc = True\n",
    "    )\n",
    "\n",
    "img = (np.random.uniform(\n",
    "    0, 255, (1,) + INPUT_SHAPE\n",
    "    ).astype(\"uint8\") / 255).astype(np.float32)\n",
    "\n",
    "%timeit model(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(5e-5)\n",
    "\n",
    "def HeatmapWeightingLoss(y_true, y_pred):\n",
    "  loss = tf.reduce_sum((y_true + 1) * tf.square(y_pred - y_true), axis=[1,2])\n",
    "  loss = tf.reduce_mean(loss)\n",
    "  return loss\n",
    "\n",
    "def heat_mae(y_true, y_pred):\n",
    "  mae = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
    "  return mae\n",
    "\n",
    "def total_loss(y_true, y_pred):\n",
    "  total_loss = ClassificationLoss(y_true, y_pred) \n",
    "  total_loss += 5 * RegrCoordsLoss(y_true, y_pred)\n",
    "  total_loss += 5 * RegrCoordsLossRaw(y_true, y_pred)\n",
    "  return total_loss\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        MODEL_PATH,\n",
    "        monitor = \"val_output_1_avgMDE_2D\",\n",
    "        save_best_only = True,\n",
    "        save_weights_only = True,\n",
    "        initial_value_threshold=None,\n",
    "        ),\n",
    "]\n",
    "\n",
    "model.compile(\n",
    "    optimizer = adam,\n",
    "    loss = {'output_1': total_loss,  'output_2': HeatmapWeightingLoss},\n",
    "    loss_weights = [5, 1],\n",
    "    metrics = {'output_1': [Accuracy, avgMDE_2D, avgMDE_2D_Raw], 'output_2': heat_mae}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"./saved_models/movenet_224.models\")\n",
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cp -r ./saved_models/* /content/gdrive/MyDrive/bodynet_ds/saved_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img, (y1, y2) in val_ds.take(1):\n",
    "    print(img.shape)\n",
    "    print(y1.shape)\n",
    "    print(y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sample(i):\n",
    "    sample = ((img[i].numpy() + 1) * 127.5).astype('uint8').copy()\n",
    "\n",
    "    coords, heatmaps = model(img[i:i+1])\n",
    "    #coords, heatmaps = postproc(y[i:i+1])\n",
    "    coords = coords[0].numpy()[:, [1,2,0]]\n",
    "\n",
    "    sample_pred = draw_keypoints(sample, coords, .01, cfg.MPII_KEYPOINT_DICT)\n",
    "    sample_orig = draw_keypoints(sample, y1[i].numpy()[:, [1,2,0]], .5, cfg.MPII_KEYPOINT_DICT)\n",
    "\n",
    "    colormap=cv2.COLORMAP_VIRIDIS\n",
    "    alpha = .5\n",
    "    \n",
    "    # Heatmaps\n",
    "    kptsmap = heatmaps[0, :, :, 1:].numpy().sum(axis=-1)\n",
    "    kptsmap = cv2.resize(kptsmap, INPUT_SHAPE[:2])\n",
    "    kptsmap =(kptsmap * 255).astype('uint8')\n",
    "    kptsmap = cv2.applyColorMap(kptsmap, colormap)\n",
    "\n",
    "    kptsmask = get_max_mask(heatmaps[:,:,:,1:])\n",
    "    kptsmask = kptsmask[0].numpy().sum(axis=-1)\n",
    "    kptsmask = cv2.resize(kptsmask, INPUT_SHAPE[:2])\n",
    "\n",
    "    centremap = heatmaps[0, :, :, 0].numpy()\n",
    "    centremap = cv2.resize(centremap, INPUT_SHAPE[:2])\n",
    "    centremap =(centremap * 255).astype('uint8')\n",
    "    centremap = cv2.applyColorMap(centremap, colormap)\n",
    "\n",
    "    # Labels\n",
    "    center_label = y2[i, :, :, 0].numpy()\n",
    "    center_label = cv2.resize(center_label, INPUT_SHAPE[:2])\n",
    "    center_label =(center_label * 255).astype('uint8')\n",
    "    center_label = cv2.applyColorMap(center_label, colormap)\n",
    "\n",
    "    kpts_label = y2[i, :, :, 1:].numpy().sum(axis=-1)\n",
    "    kpts_label = cv2.resize(kpts_label, INPUT_SHAPE[:2])\n",
    "    kpts_label =(kpts_label * 255).astype('uint8')\n",
    "    kpts_label = cv2.applyColorMap(kpts_label, colormap)\n",
    "    \n",
    "\n",
    "    fig, axs = plt.subplots(2, 2)\n",
    "    fig.set_figheight(20)\n",
    "    fig.set_figwidth(20)\n",
    "    \n",
    "    output = cv2.addWeighted(sample_orig, alpha, center_label, 1 - alpha, 0)\n",
    "    axs[0,0].imshow(output)\n",
    "    axs[0,0].axis('off')\n",
    "    axs[0,0].set_title(\"Label - CentreMap\")\n",
    "\n",
    "    output = cv2.addWeighted(sample_pred, alpha, centremap, 1 - alpha, 0)\n",
    "    axs[0,1].imshow(output)\n",
    "    axs[0,1].axis('off')\n",
    "    axs[0,1].set_title(\"Predicted - CentreMap\")\n",
    "\n",
    "    output = cv2.addWeighted(sample_orig, alpha, kpts_label, 1 - alpha, 0)\n",
    "    axs[1,0].imshow(output)\n",
    "    axs[1,0].axis('off')\n",
    "    axs[1,0].set_title(\"Label - KeypointsMap\")\n",
    "\n",
    "    output = cv2.addWeighted(sample_pred, alpha, kptsmap, 1 - alpha, 0)\n",
    "    axs[1,1].imshow(sample_pred, alpha=.5)\n",
    "    axs[1,1].imshow(kptsmask, alpha=.5)\n",
    "    axs[1,1].axis('off')\n",
    "    axs[1,1].set_title(\"Predicted - KeypointsMap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i  in range(10):\n",
    "    draw_sample(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6bf254e122c73ff488b8766148b4203e9f38b207ede26a956107a11310590f5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
